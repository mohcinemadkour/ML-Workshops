{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Lab 7: Feature Selection\n",
    "\n",
    "In this lab you will work with some of the feature selection and generation methods."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 1) Data Import and cleaning\n",
    "We will use the same data as in the previous two labs (Kaggle KDD Cup 2014) so you can use the same cleaning parts from your previous work or from lab5. You need to take all of the features to begin with or at least a large number of the features to see how feature selection methods and PCA work on them."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      ":0: FutureWarning: IPython widgets are experimental and may change in the future.\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "import pandas as pd\n",
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# Load data\n",
    "proj = pd.read_csv('data/projects.csv')\n",
    "outcomes = pd.read_csv('data/outcomes.csv')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 2) Standardization\n",
    "Standardize your features. Keep the initial version as well to compare the results. Use the same transformation for train and test data."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 3) PCA\n",
    "In this part you are going to use PCA to reduce the dimensionality of your data and extract the main components of the combination of your features. PCA is also one way for generating new features which capture the most important parts of your initial features.\n",
    "\n",
    "http://scikit-learn.org/stable/modules/generated/sklearn.decomposition.PCA.html"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 3-1 ) PCA: fixed number of components\n",
    "### Use initial features\n",
    "1- Run PCA on your data with initial features. Set the parameters to give the results with 5 components.\n",
    "\n",
    "2- Use explained-variance-ratio- to see how much of the variance in the eigen values is covered by these components.\n",
    "\n",
    "3- Use logistic regression on these components."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true
   },
   "source": [
    "### Use standardized features\n",
    "1- Run PCA on your data after standardization. Set the parameters to give the results with 5 components.\n",
    "\n",
    "2- Use explained-variance-ratio- to see how much of the variance in the eigen values is covered by these components.\n",
    "\n",
    "3- Use logistic regression on these components.\n",
    "\n",
    "### Is there a difference between your classidication results?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "from sklearn.decomposition import PCA\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 3-2 ) PCA: determine appropriate number of the components\n",
    "\n",
    "1- Use standardized features only. Run PCA on your data after standardization. Set the parameters appropriately to obtain components that cover at least 90% of the variance of the eigen values.\n",
    "\n",
    "2- Use logistic regression again.\n",
    "\n",
    "### Is there a difference between your classidication results with the previous case?\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 4) Feature Selection\n",
    "\n",
    "## 4-1) Univariate Selection\n",
    "Statistical tests can be used to select the features with strongest relationship with the output variable. You can use the SelectKBest class to select a specific number of features based on different statistical tests. Note that you can specify the score which is used to decide how good each variable is. You can use different options such as 'chi2', 'mutual-info-classif', 'SelectFpr', etc. as the score.\n",
    "\n",
    "http://scikit-learn.org/stable/modules/generated/sklearn.feature_selection.SelectKBest.html#sklearn.feature_selection.SelectKBest\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Use SelectKBest and chi^2 score\n",
    "\n",
    "Use the SelectKBest class to select 5 best features with 'chi2' score function. Try logistic regression. \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "from sklearn.feature_selection import SelectKBest\n",
    "from sklearn.feature_selection import chi2\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 4-2) Recursive Feature Elimination (RFE)\n",
    "Another approach for choosing the features is by recursively removing the extra ones using RFE. RFE uses the model accuracy to identify which combination of attributes contributes in the best way.\n",
    "\n",
    "Note that here there is this difference with SelectKBest. RFE is done integrated with your estimator because it is done iteratively based on the results of your estimator.\n",
    "\n",
    "http://scikit-learn.org/stable/modules/generated/sklearn.feature_selection.RFE.html"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true
   },
   "source": [
    "### Use RFE with logistic regression\n",
    "Use RFE to select the best 5 feaures with logistic regression."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "from sklearn.feature_selection import RFE\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 2",
   "language": "python",
   "name": "python2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
