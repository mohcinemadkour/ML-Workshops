{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "=========Introduction=========\n",
      "\n",
      "Use this code to predict the percentage tip expected after a trip in NYC green taxi. \n",
      "The code is a predictive model that was built and trained on top of the Gradient Boosting Classifer and the Random Forest Gradient both provided in scikit-learn\n",
      "\n",
      "The input: \n",
      "pandas.dataframe with columns:This should be in the same format as downloaded from the website\n",
      "\n",
      "The data frame go through the following pipeline:\n",
      "\t1. Cleaning\n",
      "\t2. Creation of derived variables\n",
      "\t3. Making predictions\n",
      "\n",
      "The output:\n",
      "\tpandas.Series, two files are saved on disk,  submission.csv and cleaned_data.csv respectively.\n",
      "\n",
      "To make predictions, run 'tip_predictor.make_predictions(data)', where data is any 2015 raw dataframe fresh from http://www.nyc.gov/html/tlc/html/about/trip_record_data.shtml\n",
      "Run tip_predictor.read_me() for further instructions\n",
      "\n"
     ]
    }
   ],
   "source": [
    "import tip_predictor\n",
    "import pandas as pd\n",
    "import os"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# Download/load the September 2015 dataset\n",
    "if os.path.exists('data_september_2015.csv'): # Check if the dataset is present on local disk and load it\n",
    "    data = pd.read_csv('data_september_2015.csv')\n",
    "else: # Download dataset if not available on disk\n",
    "    url = \"https://s3.amazonaws.com/nyc-tlc/trip+data/green_tripdata_2015-09.csv\"\n",
    "    data = pd.read_csv(url)\n",
    "    data.to_csv(url.split('/')[-1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "cleaning ...\n",
      "creating features ...\n",
      "predicting ...\n",
      "submissions and cleaned data saved as submission.csv and cleaned_data.csv respectively\n",
      "run evaluate_predictions() to compare them\n"
     ]
    }
   ],
   "source": [
    "# make predictions \n",
    "#tip_predictor.make_predictions(data.tail(1000))\n",
    "\n",
    "# uncomment the next line to run the entire dataset\n",
    "tip_predictor.make_predictions(data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "mean squared error: 10.0315724521\n",
      "r2 score: 0.888563908067\n"
     ]
    }
   ],
   "source": [
    "# compare predictions to real percentage tips\n",
    "tip_predictor.evaluate_predictions()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 2",
   "language": "python",
   "name": "python2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
